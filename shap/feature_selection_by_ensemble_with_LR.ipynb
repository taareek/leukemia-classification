{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4c2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5116ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import specificity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4349ef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1018</th>\n",
       "      <th>f_1019</th>\n",
       "      <th>f_1020</th>\n",
       "      <th>f_1021</th>\n",
       "      <th>f_1022</th>\n",
       "      <th>f_1023</th>\n",
       "      <th>f_1024</th>\n",
       "      <th>loss</th>\n",
       "      <th>label</th>\n",
       "      <th>plof_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147035</td>\n",
       "      <td>1.147716</td>\n",
       "      <td>0.107814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.014606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122150</td>\n",
       "      <td>1.559529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.758245</td>\n",
       "      <td>0.287061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>1.853845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.758245</td>\n",
       "      <td>0.287061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>1.853845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505390</td>\n",
       "      <td>0.745533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.123379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571389</td>\n",
       "      <td>0.794509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_1       f_2       f_3  f_4       f_5  f_6  f_7       f_8       f_9  \\\n",
       "0  0.147035  1.147716  0.107814  0.0  1.014606  0.0  0.0  0.122150  1.559529   \n",
       "1  0.000000  0.758245  0.287061  0.0  0.960584  0.0  0.0  0.048487  1.853845   \n",
       "2  0.000000  0.758245  0.287061  0.0  0.960584  0.0  0.0  0.048487  1.853845   \n",
       "3  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "       f_10  ...    f_1018    f_1019    f_1020  f_1021    f_1022    f_1023  \\\n",
       "0  0.000000  ...  0.000000  0.000000  0.628776     0.0  0.000000  0.000000   \n",
       "1  0.000000  ...  0.000000  0.000000  0.944606     0.0  0.000000  0.000000   \n",
       "2  0.000000  ...  0.000000  0.000000  0.944606     0.0  0.000000  0.000000   \n",
       "3  0.277865  ...  0.505390  0.745533  0.000000     0.0  0.059781  0.123379   \n",
       "4  0.183769  ...  0.571389  0.794509  0.000000     0.0  0.000000  0.000000   \n",
       "\n",
       "   f_1024      loss  label  plof_scores  \n",
       "0     0.0  0.000002      0          0.0  \n",
       "1     0.0  0.000002      0          0.0  \n",
       "2     0.0  0.000002      0          0.0  \n",
       "3     0.0  0.000002      1          0.0  \n",
       "4     0.0  0.000003      1          0.0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train data \n",
    "train_data = pd.read_csv('C:/Users/SURFACE/Desktop/Task 2/shap_code/selected_train_features_with_plof_wo_cluster.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8985a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1018</th>\n",
       "      <th>f_1019</th>\n",
       "      <th>f_1020</th>\n",
       "      <th>f_1021</th>\n",
       "      <th>f_1022</th>\n",
       "      <th>f_1023</th>\n",
       "      <th>f_1024</th>\n",
       "      <th>loss</th>\n",
       "      <th>label</th>\n",
       "      <th>plof_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622322</td>\n",
       "      <td>0.601037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572066</td>\n",
       "      <td>0.750851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384511</td>\n",
       "      <td>0.687811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123537</td>\n",
       "      <td>1.370321</td>\n",
       "      <td>0.172961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.361574</td>\n",
       "      <td>0.227110</td>\n",
       "      <td>0.04416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067586</td>\n",
       "      <td>1.144258</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948973</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.015311</td>\n",
       "      <td>1.122422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_1       f_2       f_3  f_4       f_5       f_6      f_7       f_8  \\\n",
       "0  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.00000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.00000  0.000000   \n",
       "3  0.123537  1.370321  0.172961  0.0  1.361574  0.227110  0.04416  0.000000   \n",
       "4  0.067586  1.144258  0.009396  0.0  0.948973  0.041225  0.00000  0.015311   \n",
       "\n",
       "        f_9      f_10  ...    f_1018    f_1019    f_1020  f_1021  f_1022  \\\n",
       "0  0.000000  0.271627  ...  0.622322  0.601037  0.000000     0.0     0.0   \n",
       "1  0.000000  0.273056  ...  0.572066  0.750851  0.000000     0.0     0.0   \n",
       "2  0.000000  0.163542  ...  0.384511  0.687811  0.000000     0.0     0.0   \n",
       "3  1.063966  0.000000  ...  0.000000  0.000000  0.720995     0.0     0.0   \n",
       "4  1.122422  0.000000  ...  0.000000  0.000000  0.525233     0.0     0.0   \n",
       "\n",
       "     f_1023  f_1024      loss  label  plof_scores  \n",
       "0  0.081586     0.0  0.000011      1          0.0  \n",
       "1  0.064522     0.0  0.000012      1          0.0  \n",
       "2  0.017738     0.0  0.000016      1          0.0  \n",
       "3  0.000000     0.0  0.000022      0          0.0  \n",
       "4  0.000000     0.0  0.000025      0          0.0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train data \n",
    "test_data = pd.read_csv('selected_test_features_with_plof_wo_cluster.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34dfbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After implementing uncertainty mining and pLOF, total train samples: 11200\n",
      "After implementing uncertainty mining and pLOF, total test samples: 2800\n"
     ]
    }
   ],
   "source": [
    "print(f\"After implementing uncertainty mining and pLOF, total train samples: {train_data.shape[0]}\")\n",
    "print(f\"After implementing uncertainty mining and pLOF, total test samples: {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0d5a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train features: (11200, 1024)\n",
      "shape of train labels: (11200,)\n"
     ]
    }
   ],
   "source": [
    "# droping loss columns for both train data and making labels \n",
    "train_x = pd.DataFrame(train_data.drop(['label', 'loss', 'plof_scores'], axis=1))\n",
    "train_y = train_data['label']\n",
    "print(f\"shape of train features: {train_x.shape}\")\n",
    "print(f\"shape of train labels: {train_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ec0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train features: (2800, 1024)\n",
      "shape of train labels: (2800,)\n"
     ]
    }
   ],
   "source": [
    "# droping loss columns for both train data and making labels \n",
    "test_x = pd.DataFrame(test_data.drop(['label', 'loss', 'plof_scores'], axis=1))\n",
    "test_y = test_data['label']\n",
    "print(f\"shape of train features: {test_x.shape}\")\n",
    "print(f\"shape of train labels: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9063016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform with feature scaling and compare \n",
    "# k-fold validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "def cross_validation(model, _X, _y, _cv=10):\n",
    "    '''Function to perform 5 Folds Cross-Validation\n",
    "     Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "    return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c799e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict with a specific estimator and evaluation metrices\n",
    "\n",
    "def model_prediction(ml_classifier, train_x, train_y, test_x, test_y):\n",
    "    '''\n",
    "    ml_classifier: estimator\n",
    "    name of instantiated machile learning classifier\n",
    "\n",
    "    train_x: train data \n",
    "\n",
    "    train_y: train labels\n",
    "\n",
    "    test_x: test data \n",
    "\n",
    "    test_y = test labels\n",
    "      '''\n",
    "    # fit to the model\n",
    "    ml_classifier.fit(train_x, train_y)\n",
    "\n",
    "    # prediction for test data \n",
    "    prediction = ml_classifier.predict(test_x)\n",
    "\n",
    "    # accuracy\n",
    "    acc = metrics.accuracy_score(prediction, test_y)\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(test_y, prediction)\n",
    "    print(\"ROC-AUC score is: \", round(roc_auc, 4))\n",
    "\n",
    "    # Matthew's coefficent \n",
    "    mcc = matthews_corrcoef(test_y, prediction)\n",
    "    print(\"The Matthews correlation coefficinet (MCC) is: \", round(mcc, 4))\n",
    "\n",
    "    # specificity\n",
    "    sp = specificity_score(test_y, prediction, average='weighted')\n",
    "    print(f\"Weighted specificity: {sp:.4f}\")\n",
    "\n",
    "    # classification reports \n",
    "    print(classification_report(test_y, prediction)) \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d71e6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.5, fit_intercept=True, intercept_scaling=1,\n",
    "                            class_weight=None, random_state=42, solver='lbfgs', max_iter=500, multi_class='auto', \n",
    "                            verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42c83ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 11201it [9:29:32,  3.05s/it]                              \n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "# defining shap explainer \n",
    "explainer = shap.Explainer(lr_model.predict, train_x) \n",
    "\n",
    "shap_values = explainer(train_x, max_evals=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a1353f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap of train shap values: (11200, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shap of train shap values: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a562a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(train_data.drop(['label', 'loss', 'plof_scores'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c49e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done...\n"
     ]
    }
   ],
   "source": [
    "# storing feature importance for both train and test data \n",
    "# train feature importance \n",
    "feature_importance = pd.DataFrame({'name': train_x.columns, 'importance': shap_values.abs.sum(0).values})\n",
    "feature_importance_train = feature_importance.sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "# save feature importance indexes\n",
    "feature_importance_train.to_csv(r'train_importance_lr_clf.csv', index=False)\n",
    "feature_importance = None\n",
    "print('done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5026ce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_821</td>\n",
       "      <td>431.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f_286</td>\n",
       "      <td>299.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_969</td>\n",
       "      <td>295.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f_977</td>\n",
       "      <td>278.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f_694</td>\n",
       "      <td>239.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f_392</td>\n",
       "      <td>237.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f_36</td>\n",
       "      <td>227.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f_577</td>\n",
       "      <td>222.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f_275</td>\n",
       "      <td>216.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f_358</td>\n",
       "      <td>213.715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  importance\n",
       "0  f_821     431.495\n",
       "1  f_286     299.355\n",
       "2  f_969     295.380\n",
       "3  f_977     278.395\n",
       "4  f_694     239.745\n",
       "5  f_392     237.430\n",
       "6   f_36     227.035\n",
       "7  f_577     222.165\n",
       "8  f_275     216.225\n",
       "9  f_358     213.715"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize \n",
    "feature_importance_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b26955",
   "metadata": {},
   "source": [
    "### Feature Selection and Classification Using Shaply Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76598cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_821</td>\n",
       "      <td>431.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f_286</td>\n",
       "      <td>299.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_969</td>\n",
       "      <td>295.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f_977</td>\n",
       "      <td>278.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f_694</td>\n",
       "      <td>239.745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  importance\n",
       "0  f_821     431.495\n",
       "1  f_286     299.355\n",
       "2  f_969     295.380\n",
       "3  f_977     278.395\n",
       "4  f_694     239.745"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_importance_data = pd.read_csv('train_importance_lr_clf.csv')\n",
    "f_importance_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ae64df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f3f7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making ensemble\n",
    "# defining top-5 models for ensemble based on accuracy\n",
    "\n",
    "base_estimator = LogisticRegression()\n",
    " \n",
    "\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=25, learning_rate=0.5, algorithm='SAMME.R', random_state=42, \n",
    "                                    base_estimator= base_estimator)\n",
    "\n",
    "logistic_reg_model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.5, fit_intercept=True, \n",
    "                                        intercept_scaling=1, class_weight=None, random_state=42, solver='sag', \n",
    "                                        max_iter=500, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, \n",
    "                                        l1_ratio=None)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt',\n",
    "                                max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.01, \n",
    "                        batch_size='auto', learning_rate='constant', learning_rate_init=0.1, power_t=0.5, \n",
    "                        max_iter=600, shuffle=True, random_state=42, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.8, nesterovs_momentum=True, early_stopping=False, \n",
    "                        validation_fraction=0.1, beta_1=0.7, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10,\n",
    "                        max_fun=15000)\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=35, weights='distance', algorithm='kd_tree', \n",
    "                               leaf_size=50, p=2, metric='minkowski', metric_params=None, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36ccd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking all five models into a list\n",
    "models = list()\n",
    "models.append(('adaboost', adaboost_model))\n",
    "models.append(('lr', logistic_reg_model))\n",
    "models.append(('rf', rf_model))\n",
    "models.append(('mlp', mlp_model))\n",
    "models.append(('knn', knn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7bea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for MSE loss\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e008b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(losses):\n",
    "    rms = np.sqrt(np.mean(np.square(losses)))\n",
    "    weights = [1 / (loss / rms) for loss in losses]\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5943c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate loss\n",
    "def ensemble_eval_loss(models, train_x, test_x, train_y, test_y):\n",
    "    losses = list()\n",
    "    for name, model in models:\n",
    "        print(\"fitting \\n\", model, \"\\n....\")\n",
    "        model.fit(train_x, train_y)\n",
    "        y_hat = model.predict(test_x)\n",
    "        acc = metrics.accuracy_score(test_y, y_hat)\n",
    "        loss = mse_loss(test_y, y_hat)\n",
    "        print(f\"MSE loss for {name}: {loss:.4f}\")\n",
    "        losses.append(loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3165bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(train_x, test_x, num_of_feat):\n",
    "    # making train and test set using specific number of features based on feature importance that \n",
    "    # we got from shapley values\n",
    "    print(f\"shape of train data before feature selection: {train_x.shape}\")\n",
    "    print(f\"shape of test data before feature selection: {test_x.shape}\")\n",
    "    train_x = train_x[f_importance_data.head(num_of_feat)[\"name\"]]\n",
    "    test_x = test_x[f_importance_data.head(num_of_feat)[\"name\"]]\n",
    "    print(f\"shape of train data after feature selection: {train_x.shape}\")\n",
    "    print(f\"shape of test data after feature selection: {test_x.shape}\")\n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d030dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble(models, train_x, test_x, train_y, test_y):\n",
    "    '''\n",
    "    all_loss: calculates loss of individual models in ensemble\n",
    "    \n",
    "    c_weights: calculates for individual models based on loss\n",
    "\n",
    "    train_x: train data \n",
    "\n",
    "    train_y: train labels\n",
    "\n",
    "    test_x: test data \n",
    "\n",
    "    test_y = test labels\n",
    "    \n",
    "      '''\n",
    "    all_losses = ensemble_eval_loss(models, train_x, test_x, train_y, test_y)\n",
    "    c_weights = compute_weights(all_losses)\n",
    "    ensemble = VotingClassifier(estimators=models, voting='soft', weights=c_weights)\n",
    "    ensemble.fit(train_x, train_y)\n",
    "    y_hat = ensemble.predict(test_x)\n",
    "    score = metrics.accuracy_score(test_y, y_hat)\n",
    "    print('Weighted Avg Accuracy: %.3f' % (score*100))\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10ad0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict with a specific estimator and evaluation metrices\n",
    "\n",
    "def model_prediction_with_fs(model, train_x, train_y, test_x, test_y):\n",
    "    '''\n",
    "    ml_classifier: estimator\n",
    "    name of instantiated machile learning classifier\n",
    "\n",
    "    train_x: train data \n",
    "\n",
    "    train_y: train labels\n",
    "\n",
    "    test_x: test data \n",
    "\n",
    "    test_y = test labels\n",
    "    \n",
    "      '''\n",
    "    \n",
    "    # fit to the model\n",
    "#     ml_classifier.fit(train_x, train_y)\n",
    "\n",
    "    # prediction for test data \n",
    "    prediction = model.predict(test_x)\n",
    "\n",
    "    # accuracy\n",
    "    acc = metrics.accuracy_score(prediction, test_y)\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(test_y, prediction)\n",
    "    print(\"ROC-AUC score is: \", round(roc_auc, 3))\n",
    "\n",
    "    # Matthew's coefficent \n",
    "    mcc = matthews_corrcoef(test_y, prediction)\n",
    "    print(\"The Matthews correlation coefficinet (MCC) is: \", round(mcc, 3))\n",
    "\n",
    "    # specificity\n",
    "    sp = specificity_score(test_y, prediction, average='weighted')\n",
    "    print(f\"Weighted specificity: {sp:.3f}\")\n",
    "\n",
    "    # classification reports \n",
    "    print(classification_report(test_y, prediction)) \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a8e0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, num_of_feat, _X, _y, _cv=10):\n",
    "    '''Function to perform 5 Folds Cross-Validation\n",
    "     Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "    # get selected features \n",
    "    _X = _X[f_importance_data.head(num_of_feat)[\"name\"]]\n",
    "    print(f\"shape of train data after feature selection: {_X.shape}\")\n",
    "    \n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "    return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d862e9",
   "metadata": {},
   "source": [
    "#### 100 feartues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e4a57dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 100)\n",
      "shape of test data after feature selection: (2800, 100)\n"
     ]
    }
   ],
   "source": [
    "train_100, test_100 = select_features(train_x, test_x, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3e7c068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0868\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0821\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0879\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0875\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0904\n",
      "Weighted Avg Accuracy: 91.536\n"
     ]
    }
   ],
   "source": [
    "ensemble_100 = build_ensemble(models, train_100, test_100, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fc127f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('adaboost',\n",
       "                              AdaBoostClassifier(base_estimator=LogisticRegression(),\n",
       "                                                 learning_rate=0.5,\n",
       "                                                 n_estimators=25,\n",
       "                                                 random_state=42)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=0.5, max_iter=500,\n",
       "                                                 random_state=42,\n",
       "                                                 solver='sag')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_features='sqrt')),\n",
       "                             ('mlp',\n",
       "                              MLPClassifier(alpha=0.01, beta_1=0.7,\n",
       "                                            learning_rate_init=0.1,\n",
       "                                            max_iter=600, momentum=0.8,\n",
       "                                            random_state=42)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   leaf_size=50, n_neighbors=35,\n",
       "                                                   weights='distance'))],\n",
       "                 voting='soft',\n",
       "                 weights=[1.002121409821362, 1.0587630547243085,\n",
       "                          0.9899004170186624, 0.9939408268840447,\n",
       "                          0.9625118679311896])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4f1c967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.9703373 , 0.97718254, 0.97748016, 0.9719246 , 0.97549603,\n",
       "        0.97628968, 0.97549603, 0.97142857, 0.97470238, 0.97539683]),\n",
       " 'Mean Training Accuracy': 97.45734126984127,\n",
       " 'Training Precision scores': array([0.97495961, 0.97969849, 0.97816944, 0.97237237, 0.97769741,\n",
       "        0.97696775, 0.97943134, 0.97121152, 0.98134253, 0.9744511 ]),\n",
       " 'Mean Training Precision': 0.976630155429075,\n",
       " 'Training Recall scores': array([0.96502099, 0.97421547, 0.97640944, 0.9710116 , 0.97281088,\n",
       "        0.97520992, 0.9710116 , 0.97121152, 0.96741303, 0.9760096 ]),\n",
       " 'Mean Training Recall': 0.9720324023099135,\n",
       " 'Training F1 scores': array([0.96996484, 0.97694929, 0.97728864, 0.97169151, 0.97524802,\n",
       "        0.97608804, 0.97520329, 0.97121152, 0.974328  , 0.97522972]),\n",
       " 'Mean Training F1 Score': 0.9743202877013324,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99821429, 0.75803571, 0.89196429, 0.92142857,\n",
       "        0.90892857, 0.91964286, 0.9125    , 0.91696429, 0.92678571]),\n",
       " 'Mean Validation Accuracy': 91.54464285714286,\n",
       " 'Validation Precision scores': array([1.        , 0.99640934, 0.73869347, 0.88224956, 0.92857143,\n",
       "        0.93155894, 0.93470149, 0.92407407, 0.93927894, 0.93566176]),\n",
       " 'Mean Validation Precision': 0.9211198996327801,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.79316547, 0.9028777 , 0.9118705 ,\n",
       "        0.88129496, 0.90107914, 0.89748201, 0.89028777, 0.91546763]),\n",
       " 'Mean Validation Recall': 0.9093525179856116,\n",
       " 'Validation F1 scores': array([1.        , 0.99820144, 0.76496097, 0.89244444, 0.92014519,\n",
       "        0.90573013, 0.91758242, 0.91058394, 0.91412742, 0.92545455]),\n",
       " 'Mean Validation F1 Score': 0.9149230503090525}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_100, 100, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0039e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9153571428571429\n",
      "ROC-AUC score is:  0.915\n",
      "The Matthews correlation coefficinet (MCC) is:  0.831\n",
      "Weighted specificity: 0.915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      1423\n",
      "           1       0.92      0.91      0.91      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_100 = model_prediction_with_fs(ensemble_100, train_100, train_y, test_100, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028fdaa",
   "metadata": {},
   "source": [
    "#### 200 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4f6784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 200)\n",
      "shape of test data after feature selection: (2800, 200)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0861\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0825\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0875\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0836\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0882\n",
      "Weighted Avg Accuracy: 91.821\n"
     ]
    }
   ],
   "source": [
    "train_200, test_200 = select_features(train_x, test_x, 200)\n",
    "ensemble_200 = build_ensemble(models, train_200, test_200, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "752333da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97430556, 0.97529762, 0.97619048, 0.97559524, 0.975     ,\n",
       "        0.97440476, 0.98253968, 0.98293651, 0.975     , 0.97400794]),\n",
       " 'Mean Training Accuracy': 97.65277777777777,\n",
       " 'Training Precision scores': array([0.97726358, 0.97069307, 0.98473127, 0.97866345, 0.98057467,\n",
       "        0.9766881 , 0.98317982, 0.98396794, 0.97999192, 0.97975709]),\n",
       " 'Mean Training Precision': 0.9795510888826433,\n",
       " 'Training Recall scores': array([0.97081751, 0.97981211, 0.96701319, 0.9720112 , 0.96881248,\n",
       "        0.97161136, 0.98160736, 0.98160736, 0.96941224, 0.96761295]),\n",
       " 'Mean Training Recall': 0.9730317746976764,\n",
       " 'Training F1 scores': array([0.97402988, 0.97523127, 0.97579181, 0.97532598, 0.97465809,\n",
       "        0.97414311, 0.98239296, 0.98278623, 0.97467337, 0.97364715]),\n",
       " 'Mean Training F1 Score': 0.9762679849041065,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99732143, 0.77767857, 0.89375   , 0.92232143,\n",
       "        0.90982143, 0.92053571, 0.90982143, 0.92410714, 0.92857143]),\n",
       " 'Mean Validation Accuracy': 91.83928571428572,\n",
       " 'Validation Precision scores': array([1.        , 0.99462366, 0.78268877, 0.88948307, 0.93506494,\n",
       "        0.93834297, 0.93001842, 0.92364991, 0.93370166, 0.95419847]),\n",
       " 'Mean Validation Precision': 0.9281771844128848,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.76438849, 0.89748201, 0.90647482,\n",
       "        0.87589928, 0.90827338, 0.89208633, 0.9118705 , 0.89928058]),\n",
       " 'Mean Validation Recall': 0.9055755395683454,\n",
       " 'Validation F1 scores': array([1.        , 0.99730458, 0.77343039, 0.89346464, 0.92054795,\n",
       "        0.90604651, 0.91901729, 0.90759378, 0.92265696, 0.92592593]),\n",
       " 'Mean Validation F1 Score': 0.9165988021564602}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_200, 200, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d256769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182142857142858\n",
      "ROC-AUC score is:  0.918\n",
      "The Matthews correlation coefficinet (MCC) is:  0.837\n",
      "Weighted specificity: 0.918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1423\n",
      "           1       0.93      0.91      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_200 = model_prediction_with_fs(ensemble_200, train_200, train_y, test_200, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561be97c",
   "metadata": {},
   "source": [
    "#### 300 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "646c995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 300)\n",
      "shape of test data after feature selection: (2800, 300)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0857\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0814\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0832\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.1007\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0879\n",
      "Weighted Avg Accuracy: 91.929\n"
     ]
    }
   ],
   "source": [
    "train_300, test_300 = select_features(train_x, test_x, 300)\n",
    "ensemble_300 = build_ensemble(models, train_300, test_300, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f248fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97480159, 0.9796627 , 0.98194444, 0.97926587, 0.98144841,\n",
       "        0.9780754 , 0.97738095, 0.97837302, 0.98125   , 0.97956349]),\n",
       " 'Mean Training Accuracy': 97.91765873015873,\n",
       " 'Training Precision scores': array([0.97998787, 0.97865124, 0.98706548, 0.98035678, 0.98236826,\n",
       "        0.98577525, 0.98125   , 0.98421053, 0.982942  , 0.98210696]),\n",
       " 'Mean Training Precision': 0.9824714371501375,\n",
       " 'Training Recall scores': array([0.96901859, 0.98041175, 0.97640944, 0.97780888, 0.98020792,\n",
       "        0.96981208, 0.9730108 , 0.9720112 , 0.97920832, 0.97660936]),\n",
       " 'Mean Training Recall': 0.9754508310607397,\n",
       " 'Training F1 scores': array([0.97447236, 0.9795307 , 0.98170854, 0.97908117, 0.9812869 ,\n",
       "        0.97772851, 0.97711303, 0.97807282, 0.98107161, 0.97935044]),\n",
       " 'Mean Training F1 Score': 0.9789416092227906,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99642857, 0.76875   , 0.89285714, 0.92410714,\n",
       "        0.90803571, 0.91875   , 0.90892857, 0.92232143, 0.93035714]),\n",
       " 'Mean Validation Accuracy': 91.70535714285715,\n",
       " 'Validation Precision scores': array([1.        , 0.99284436, 0.75647668, 0.88790036, 0.92896175,\n",
       "        0.94152047, 0.93457944, 0.92669173, 0.92714026, 0.94259259]),\n",
       " 'Mean Validation Precision': 0.923870763739458,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.78776978, 0.89748201, 0.91726619,\n",
       "        0.86870504, 0.89928058, 0.88669065, 0.91546763, 0.91546763]),\n",
       " 'Mean Validation Recall': 0.9088129496402878,\n",
       " 'Validation F1 scores': array([1.        , 0.99640934, 0.77180617, 0.89266547, 0.92307692,\n",
       "        0.90364827, 0.91659028, 0.90625   , 0.92126697, 0.92883212]),\n",
       " 'Mean Validation F1 Score': 0.9160545538933501}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_300, 300, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab53eb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9192857142857143\n",
      "ROC-AUC score is:  0.919\n",
      "The Matthews correlation coefficinet (MCC) is:  0.839\n",
      "Weighted specificity: 0.919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1423\n",
      "           1       0.92      0.91      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_300 = model_prediction_with_fs(ensemble_300, train_300, train_y, test_300, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4a7a7",
   "metadata": {},
   "source": [
    "#### 400 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f12ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 400)\n",
      "shape of test data after feature selection: (2800, 400)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0854\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0804\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0857\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0832\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0861\n",
      "Weighted Avg Accuracy: 91.821\n"
     ]
    }
   ],
   "source": [
    "train_400, test_400 = select_features(train_x, test_x, 400)\n",
    "ensemble_400 = build_ensemble(models, train_400, test_400, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c7a590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97480159, 0.97619048, 0.97847222, 0.97222222, 0.97867063,\n",
       "        0.97400794, 0.97539683, 0.97321429, 0.9781746 , 0.9734127 ]),\n",
       " 'Mean Training Accuracy': 97.54563492063491,\n",
       " 'Training Precision scores': array([0.97652017, 0.97888598, 0.98856443, 0.97050618, 0.98757384,\n",
       "        0.98446443, 0.97769293, 0.97875354, 0.98069964, 0.9783751 ]),\n",
       " 'Mean Training Precision': 0.980203623982483,\n",
       " 'Training Recall scores': array([0.97261643, 0.97301619, 0.96781287, 0.97361056, 0.96921232,\n",
       "        0.96281487, 0.97261096, 0.96701319, 0.97520992, 0.96781287]),\n",
       " 'Mean Training Recall': 0.9701730181403352,\n",
       " 'Training F1 scores': array([0.97456439, 0.97594226, 0.97807859, 0.97205589, 0.97830693,\n",
       "        0.9735193 , 0.97514532, 0.97284795, 0.97794707, 0.97306533]),\n",
       " 'Mean Training F1 Score': 0.9751473037738982,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99821429, 0.77053571, 0.89464286, 0.92053571,\n",
       "        0.90803571, 0.91785714, 0.91160714, 0.91964286, 0.92767857]),\n",
       " 'Mean Validation Accuracy': 91.68750000000001,\n",
       " 'Validation Precision scores': array([1.        , 0.99640934, 0.77634011, 0.88421053, 0.93320965,\n",
       "        0.94674556, 0.93283582, 0.92870544, 0.92673993, 0.9489603 ]),\n",
       " 'Mean Validation Precision': 0.9274156673567646,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.75539568, 0.90647482, 0.90467626,\n",
       "        0.86330935, 0.89928058, 0.89028777, 0.91007194, 0.9028777 ]),\n",
       " 'Mean Validation Recall': 0.9032374100719422,\n",
       " 'Validation F1 scores': array([1.        , 0.99820144, 0.7657247 , 0.89520426, 0.91872146,\n",
       "        0.90310442, 0.91575092, 0.90909091, 0.91833031, 0.92534562]),\n",
       " 'Mean Validation F1 Score': 0.9149474043591359}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_400, 400, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2f04f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182142857142858\n",
      "ROC-AUC score is:  0.918\n",
      "The Matthews correlation coefficinet (MCC) is:  0.836\n",
      "Weighted specificity: 0.918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1423\n",
      "           1       0.92      0.91      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_400 = model_prediction_with_fs(ensemble_400, train_400, train_y, test_400, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62e125",
   "metadata": {},
   "source": [
    "#### 500 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffa2e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 500)\n",
      "shape of test data after feature selection: (2800, 500)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0871\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0814\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0850\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0857\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0850\n",
      "Weighted Avg Accuracy: 91.786\n"
     ]
    }
   ],
   "source": [
    "train_500, test_500 = select_features(train_x, test_x, 500)\n",
    "ensemble_500 = build_ensemble(models, train_500, test_500, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f2a1cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97539683, 0.97490079, 0.98005952, 0.97579365, 0.97628968,\n",
       "        0.97549603, 0.97331349, 0.97668651, 0.97728175, 0.97698413]),\n",
       " 'Mean Training Accuracy': 97.6220238095238,\n",
       " 'Training Precision scores': array([0.9805943 , 0.97424121, 0.98309519, 0.97637165, 0.97907866,\n",
       "        0.97962477, 0.97606115, 0.98083518, 0.98339072, 0.98377282]),\n",
       " 'Mean Training Precision': 0.9797065658892663,\n",
       " 'Training Recall scores': array([0.96961823, 0.97521487, 0.97660936, 0.97481008, 0.9730108 ,\n",
       "        0.97081168, 0.970012  , 0.9720112 , 0.97061176, 0.96961216]),\n",
       " 'Mean Training Recall': 0.9722322104538156,\n",
       " 'Training F1 scores': array([0.97507538, 0.9747278 , 0.97984154, 0.97559024, 0.9760353 ,\n",
       "        0.97519831, 0.97302717, 0.97640325, 0.97695945, 0.97664116]),\n",
       " 'Mean Training F1 Score': 0.9759499600503048,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99821429, 0.77410714, 0.89107143, 0.92232143,\n",
       "        0.90714286, 0.91517857, 0.91071429, 0.91785714, 0.92589286]),\n",
       " 'Mean Validation Accuracy': 91.625,\n",
       " 'Validation Precision scores': array([1.        , 0.99640934, 0.76165803, 0.88475177, 0.93027523,\n",
       "        0.93461538, 0.93084112, 0.9351145 , 0.93445693, 0.9592233 ]),\n",
       " 'Mean Validation Precision': 0.9267345608959967,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.79316547, 0.89748201, 0.9118705 ,\n",
       "        0.87410072, 0.89568345, 0.88129496, 0.89748201, 0.88848921]),\n",
       " 'Mean Validation Recall': 0.9039568345323741,\n",
       " 'Validation F1 scores': array([1.        , 0.99820144, 0.77709251, 0.89107143, 0.92098093,\n",
       "        0.90334572, 0.91292392, 0.90740741, 0.91559633, 0.92250233]),\n",
       " 'Mean Validation F1 Score': 0.9149122024727239}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_500, 500, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47844601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9178571428571428\n",
      "ROC-AUC score is:  0.918\n",
      "The Matthews correlation coefficinet (MCC) is:  0.836\n",
      "Weighted specificity: 0.917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1423\n",
      "           1       0.93      0.90      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_500 = model_prediction_with_fs(ensemble_500, train_500, train_y, test_500, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c6d76",
   "metadata": {},
   "source": [
    "#### 600 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d4380d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 600)\n",
      "shape of test data after feature selection: (2800, 600)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0879\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0804\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0871\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0861\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0864\n",
      "Weighted Avg Accuracy: 91.607\n"
     ]
    }
   ],
   "source": [
    "train_600, test_600 = select_features(train_x, test_x, 600)\n",
    "ensemble_600 = build_ensemble(models, train_600, test_600, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9621cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97390873, 0.98045635, 0.9796627 , 0.97857143, 0.98055556,\n",
       "        0.97668651, 0.97519841, 0.97619048, 0.97837302, 0.97886905]),\n",
       " 'Mean Training Accuracy': 97.78472222222221,\n",
       " 'Training Precision scores': array([0.97743755, 0.97983227, 0.98230444, 0.98362975, 0.98565077,\n",
       "        0.97890295, 0.97482014, 0.98081583, 0.98090068, 0.9795714 ]),\n",
       " 'Mean Training Precision': 0.9803865793084459,\n",
       " 'Training Recall scores': array([0.96981811, 0.98081151, 0.97660936, 0.9730108 , 0.97501   ,\n",
       "        0.9740104 , 0.97520992, 0.9710116 , 0.97540984, 0.97780888]),\n",
       " 'Mean Training Recall': 0.9748710389919587,\n",
       " 'Training F1 scores': array([0.97361292, 0.98032165, 0.97944862, 0.97829146, 0.98030151,\n",
       "        0.97645055, 0.97501499, 0.97588909, 0.97814755, 0.97868934]),\n",
       " 'Mean Training F1 Score': 0.9776167680979618,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99732143, 0.76517857, 0.89642857, 0.92232143,\n",
       "        0.91071429, 0.91785714, 0.90892857, 0.91964286, 0.92767857]),\n",
       " 'Mean Validation Accuracy': 91.66071428571429,\n",
       " 'Validation Precision scores': array([1.        , 0.99462366, 0.74788494, 0.89855072, 0.93345656,\n",
       "        0.93181818, 0.92647059, 0.92669173, 0.92673993, 0.9373849 ]),\n",
       " 'Mean Validation Precision': 0.9223621208079944,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.79496403, 0.89208633, 0.90827338,\n",
       "        0.88489209, 0.90647482, 0.88669065, 0.91007194, 0.91546763]),\n",
       " 'Mean Validation Recall': 0.9098920863309352,\n",
       " 'Validation F1 scores': array([1.        , 0.99730458, 0.77070619, 0.89530686, 0.9206928 ,\n",
       "        0.90774908, 0.91636364, 0.90625   , 0.91833031, 0.92629663]),\n",
       " 'Mean Validation F1 Score': 0.9159000085705886}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_600, 600, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c915060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9160714285714285\n",
      "ROC-AUC score is:  0.916\n",
      "The Matthews correlation coefficinet (MCC) is:  0.832\n",
      "Weighted specificity: 0.915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1423\n",
      "           1       0.93      0.90      0.91      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_600 = model_prediction_with_fs(ensemble_600, train_600, train_y, test_600, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29116127",
   "metadata": {},
   "source": [
    "#### 700 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0683d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 700)\n",
      "shape of test data after feature selection: (2800, 700)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0879\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0800\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0839\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0829\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0857\n",
      "Weighted Avg Accuracy: 91.929\n"
     ]
    }
   ],
   "source": [
    "train_700, test_700 = select_features(train_x, test_x, 700)\n",
    "ensemble_700 = build_ensemble(models, train_700, test_700, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0930475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 700)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97162698, 0.97867063, 0.97886905, 0.97589286, 0.97371032,\n",
       "        0.97083333, 0.9764881 , 0.97450397, 0.97748016, 0.97549603]),\n",
       " 'Mean Training Accuracy': 97.53571428571428,\n",
       " 'Training Precision scores': array([0.97445182, 0.97368421, 0.98111312, 0.97504492, 0.97993921,\n",
       "        0.97136564, 0.98375635, 0.97919612, 0.97855282, 0.97712222]),\n",
       " 'Mean Training Precision': 0.9774226417979349,\n",
       " 'Training Recall scores': array([0.96821907, 0.98360983, 0.97620952, 0.97640944, 0.96681327,\n",
       "        0.96981208, 0.96861255, 0.96921232, 0.9760096 , 0.97341064]),\n",
       " 'Mean Training Recall': 0.972831830689671,\n",
       " 'Training F1 scores': array([0.97132545, 0.97862186, 0.97865518, 0.9757267 , 0.97333199,\n",
       "        0.97058824, 0.97612572, 0.97417864, 0.97727955, 0.97526289]),\n",
       " 'Mean Training F1 Score': 0.9751096208207191,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99732143, 0.76607143, 0.89464286, 0.92589286,\n",
       "        0.91071429, 0.91607143, 0.90982143, 0.92232143, 0.92410714]),\n",
       " 'Mean Validation Accuracy': 91.66964285714286,\n",
       " 'Validation Precision scores': array([1.        , 0.99462366, 0.75085324, 0.8815331 , 0.93235832,\n",
       "        0.9351145 , 0.93584906, 0.93333333, 0.92558984, 0.94517958]),\n",
       " 'Mean Validation Precision': 0.9234434631914313,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.79136691, 0.91007194, 0.91726619,\n",
       "        0.88129496, 0.89208633, 0.88129496, 0.91726619, 0.89928058]),\n",
       " 'Mean Validation Recall': 0.9089928057553956,\n",
       " 'Validation F1 scores': array([1.        , 0.99730458, 0.77057793, 0.89557522, 0.92475068,\n",
       "        0.90740741, 0.91344383, 0.90656799, 0.92140921, 0.92165899]),\n",
       " 'Mean Validation F1 Score': 0.9158695847708014}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_700, 700, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30341e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9192857142857143\n",
      "ROC-AUC score is:  0.919\n",
      "The Matthews correlation coefficinet (MCC) is:  0.839\n",
      "Weighted specificity: 0.919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1423\n",
      "           1       0.93      0.91      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_700 = model_prediction_with_fs(ensemble_700, train_700, train_y, test_700, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a77499",
   "metadata": {},
   "source": [
    "#### 800 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09204135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 800)\n",
      "shape of test data after feature selection: (2800, 800)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0864\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0796\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0857\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0846\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0846\n",
      "Weighted Avg Accuracy: 91.821\n"
     ]
    }
   ],
   "source": [
    "train_800, test_800 = select_features(train_x, test_x, 800)\n",
    "ensemble_800 = build_ensemble(models, train_800, test_800, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1aac014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.96865079, 0.97261905, 0.97906746, 0.97559524, 0.97549603,\n",
       "        0.97628968, 0.97847222, 0.97986111, 0.97996032, 0.97757937]),\n",
       " 'Mean Training Accuracy': 97.6359126984127,\n",
       " 'Training Precision scores': array([0.96879376, 0.97241655, 0.98247734, 0.9756    , 0.98451192,\n",
       "        0.97639528, 0.97897898, 0.986418  , 0.98      , 0.97664671]),\n",
       " 'Mean Training Precision': 0.9782238537793798,\n",
       " 'Training Recall scores': array([0.96801919, 0.97241655, 0.97520992, 0.97520992, 0.96581367,\n",
       "        0.97580968, 0.97760896, 0.97281088, 0.97960816, 0.97820872]),\n",
       " 'Mean Training Recall': 0.9740715626601648,\n",
       " 'Training F1 scores': array([0.96840632, 0.97241655, 0.97883014, 0.97540492, 0.97507317,\n",
       "        0.97610239, 0.97829349, 0.97956719, 0.97980404, 0.97742709]),\n",
       " 'Mean Training F1 Score': 0.976132528429973,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99910714, 0.77321429, 0.89196429, 0.92142857,\n",
       "        0.90892857, 0.91785714, 0.90803571, 0.92232143, 0.92589286]),\n",
       " 'Mean Validation Accuracy': 91.68750000000001,\n",
       " 'Validation Precision scores': array([1.        , 0.99820144, 0.7630662 , 0.88224956, 0.93014706,\n",
       "        0.92830189, 0.93122677, 0.92816635, 0.93186004, 0.93235832]),\n",
       " 'Mean Validation Precision': 0.9225577619525378,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.78776978, 0.9028777 , 0.91007194,\n",
       "        0.88489209, 0.90107914, 0.88309353, 0.91007194, 0.91726619]),\n",
       " 'Mean Validation Recall': 0.9097122302158273,\n",
       " 'Validation F1 scores': array([1.        , 0.99909991, 0.77522124, 0.89244444, 0.92      ,\n",
       "        0.90607735, 0.91590494, 0.90506912, 0.92083712, 0.92475068]),\n",
       " 'Mean Validation F1 Score': 0.9159404806500898}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_800, 800, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c375162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182142857142858\n",
      "ROC-AUC score is:  0.918\n",
      "The Matthews correlation coefficinet (MCC) is:  0.836\n",
      "Weighted specificity: 0.918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1423\n",
      "           1       0.92      0.91      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_800 = model_prediction_with_fs(ensemble_800, train_800, train_y, test_800, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3fa784",
   "metadata": {},
   "source": [
    "#### 900 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec28ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data before feature selection: (11200, 1024)\n",
      "shape of test data before feature selection: (2800, 1024)\n",
      "shape of train data after feature selection: (11200, 900)\n",
      "shape of test data after feature selection: (2800, 900)\n",
      "fitting \n",
      " AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.5,\n",
      "                   n_estimators=25, random_state=42) \n",
      "....\n",
      "MSE loss for adaboost: 0.0868\n",
      "fitting \n",
      " LogisticRegression(C=0.5, max_iter=500, random_state=42, solver='sag') \n",
      "....\n",
      "MSE loss for lr: 0.0793\n",
      "fitting \n",
      " RandomForestClassifier(max_features='sqrt') \n",
      "....\n",
      "MSE loss for rf: 0.0850\n",
      "fitting \n",
      " MLPClassifier(alpha=0.01, beta_1=0.7, learning_rate_init=0.1, max_iter=600,\n",
      "              momentum=0.8, random_state=42) \n",
      "....\n",
      "MSE loss for mlp: 0.0829\n",
      "fitting \n",
      " KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=35,\n",
      "                     weights='distance') \n",
      "....\n",
      "MSE loss for knn: 0.0843\n",
      "Weighted Avg Accuracy: 91.893\n"
     ]
    }
   ],
   "source": [
    "train_900, test_900 = select_features(train_x, test_x, 900)\n",
    "ensemble_900 = build_ensemble(models, train_900, test_900, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b96b978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after feature selection: (11200, 900)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.97311508, 0.97986111, 0.97857143, 0.98105159, 0.98005952,\n",
       "        0.97698413, 0.9781746 , 0.98085317, 0.97886905, 0.97698413]),\n",
       " 'Mean Training Accuracy': 97.84523809523809,\n",
       " 'Training Precision scores': array([0.9824633 , 0.97961631, 0.98480551, 0.97548923, 0.97695212,\n",
       "        0.98240291, 0.97973515, 0.97529156, 0.9846185 , 0.97795591]),\n",
       " 'Mean Training Precision': 0.9799330490722037,\n",
       " 'Training Recall scores': array([0.96302219, 0.97981211, 0.97181128, 0.98660536, 0.9830068 ,\n",
       "        0.9710116 , 0.97620952, 0.98640544, 0.97261096, 0.97560976]),\n",
       " 'Mean Training Recall': 0.976610499114366,\n",
       " 'Training F1 scores': array([0.9726456 , 0.9797142 , 0.97826524, 0.9810158 , 0.9799701 ,\n",
       "        0.97667404, 0.97796916, 0.98081702, 0.97857789, 0.97678143]),\n",
       " 'Mean Training F1 Score': 0.9782430488897701,\n",
       " 'Validation Accuracy scores': array([1.        , 0.99821429, 0.77321429, 0.89553571, 0.92053571,\n",
       "        0.90714286, 0.91875   , 0.91160714, 0.92053571, 0.92946429]),\n",
       " 'Mean Validation Accuracy': 91.75000000000001,\n",
       " 'Validation Precision scores': array([1.        , 0.99640934, 0.76124567, 0.88041594, 0.91921005,\n",
       "        0.93629344, 0.93296089, 0.91621129, 0.93320965, 0.94085028]),\n",
       " 'Mean Validation Precision': 0.921680655703663,\n",
       " 'Validation Recall scores': array([1.        , 1.        , 0.79136691, 0.91366906, 0.92086331,\n",
       "        0.87230216, 0.90107914, 0.90467626, 0.90467626, 0.91546763]),\n",
       " 'Mean Validation Recall': 0.9124100719424459,\n",
       " 'Validation F1 scores': array([1.        , 0.99820144, 0.77601411, 0.89673433, 0.92003594,\n",
       "        0.90316574, 0.91674291, 0.91040724, 0.91872146, 0.92798541]),\n",
       " 'Mean Validation F1 Score': 0.9168008581493107}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(ensemble_900, 900, train_x, train_y, _cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27932740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9189285714285714\n",
      "ROC-AUC score is:  0.919\n",
      "The Matthews correlation coefficinet (MCC) is:  0.838\n",
      "Weighted specificity: 0.918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1423\n",
      "           1       0.93      0.91      0.92      1377\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_900 = model_prediction_with_fs(ensemble_900, train_900, train_y, test_900, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb59e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
